# xupr-drl
Manually construct a comprehensive DRL model which use all state-of-the-art techniques

## Environment

We use [OhmniInSpacev0](https://github.com/tphanson/tf-agent-labs/tree/c51)

## Checklist
- [ ] Q-Learning
- [ ] Deep Q-Learning (Add CNN)
- [ ] Deep Recurrent Q-Learning (Add RNN)
- [ ] Prioritized Experience Replay
- [ ] Double Q-Learning
- [ ] Dueling Networks
- [ ] Multi-steps Learning
- [ ] Distributional Reinforcement Learning
- [ ] Distributed Learning

## References

[1] Hessel, M., et al. "Rainbow: Combining Improvements in Deep Reinforcement Learning. ArXiv e-prints (Oct." arXiv preprint cs.AI/1710.02298 (2017).

[2] Horgan, Dan, et al. "Distributed prioritized experience replay." arXiv preprint arXiv:1803.00933 (2018).

[3] Kapturowski, Steven, et al. "Recurrent experience replay in distributed reinforcement learning." International conference on learning representations. 2018.
