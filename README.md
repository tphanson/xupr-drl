# xupr-drl
Manually construct a comprehensive DRL model which use all state-of-the-art techniques

## Environment

We use [OhmniInSpacev0](https://github.com/tphanson/tf-agent-labs/tree/c51)

## Checklist
- [x] Q-Learning
- [x] Deep Q-Learning (Add CNN)
- [x] Deep Recurrent Q-Learning (Add RNN)
- [x] Prioritized Experience Replay
- [x] Double Q-Learning
- [ ] Dueling Networks
- [x] Multi-steps Learning
- [x] Distributional Reinforcement Learning
- [ ] Distributed Learning

## References

[1] Hessel, Matteo, et al. "Rainbow: Combining improvements in deep reinforcement learning." Proceedings of the AAAI Conference on Artificial Intelligence. Vol. 32. No. 1. 2018.

[2] Horgan, Dan, et al. "Distributed prioritized experience replay." arXiv preprint arXiv:1803.00933 (2018).

[3] Kapturowski, Steven, et al. "Recurrent experience replay in distributed reinforcement learning." International conference on learning representations. 2018.

[4] Tomassoli, Massimiliano. “Distributional RL.” Simple Machine Learning, mtomassoli.github.io/2017/12/08/distributional_rl/.